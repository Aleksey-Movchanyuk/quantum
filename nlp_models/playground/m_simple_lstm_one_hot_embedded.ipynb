{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### import numpy as np\n",
    "import gensim\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.utils import np_utils\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import plot,model_to_dot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpora: 26\n"
     ]
    }
   ],
   "source": [
    "corpora = gensim.corpora.Dictionary.load('./data/corpora.dat')\n",
    "vocab_size = len(corpora)\n",
    "print('Number of words in corpora: %d'%(vocab_size))\n",
    "tmp = list(corpora.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the_filename = './data/wonderland.txt.dat'\n",
    "the_filename = './data/test.txt.dat'\n",
    "with open(the_filename, 'rb') as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate words patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, len(text)-seq_length, 1):\n",
    "    seq_in = text[i:i+seq_length]\n",
    "    seq_out = text[i+seq_length]\n",
    "    dataX.append(seq_in)\n",
    "    dataY.append(seq_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = Embedding(input_dim=vocab_size, output_dim=4, input_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_1 = LSTM(50)\n",
    "#lstm_1 = LSTM(50, input_length=seq_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_layer = Dense(output_dim=vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential(layers=[emb, lstm_1, out_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 2, 4)          104         embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 50)            11000       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 26)            1326        lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 12430\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"264pt\" viewBox=\"0.00 0.00 206.00 264.00\" width=\"206pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-260 202,-260 202,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140685709883824 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140685709883824</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 198,-255.5 198,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-233.8\">embedding_input_2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140685709884608 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140685709884608</title>\n",
       "<polygon fill=\"none\" points=\"15.5,-146.5 15.5,-182.5 182.5,-182.5 182.5,-146.5 15.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-160.8\">embedding_2 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140685709883824&#45;&gt;140685709884608 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140685709883824-&gt;140685709884608</title>\n",
       "<path d=\"M99,-219.313C99,-211.289 99,-201.547 99,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"102.5,-192.529 99,-182.529 95.5001,-192.529 102.5,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140685709883600 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140685709883600</title>\n",
       "<polygon fill=\"none\" points=\"47,-73.5 47,-109.5 151,-109.5 151,-73.5 47,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-87.8\">lstm_2 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140685709884608&#45;&gt;140685709883600 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140685709884608-&gt;140685709883600</title>\n",
       "<path d=\"M99,-146.313C99,-138.289 99,-128.547 99,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"102.5,-119.529 99,-109.529 95.5001,-119.529 102.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140685709884328 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140685709884328</title>\n",
       "<polygon fill=\"none\" points=\"45.5,-0.5 45.5,-36.5 152.5,-36.5 152.5,-0.5 45.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-14.8\">dense_2 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140685709883600&#45;&gt;140685709884328 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140685709883600-&gt;140685709884328</title>\n",
       "<path d=\"M99,-73.3129C99,-65.2895 99,-55.5475 99,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"102.5,-46.5288 99,-36.5288 95.5001,-46.5289 102.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (len(dataX), seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 26)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np_utils.to_categorical(dataY)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.2642 - acc: 0.0000e+00Epoch 00000: acc improved from -inf to 0.00000, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.2633 - acc: 0.0000e+00     \n",
      "Epoch 2/50\n",
      "22/28 [======================>.......] - ETA: 0s - loss: 3.2546 - acc: 0.0455Epoch 00001: acc improved from 0.00000 to 0.07143, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.2536 - acc: 0.0714     \n",
      "Epoch 3/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.2472 - acc: 0.1154Epoch 00002: acc improved from 0.07143 to 0.10714, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.2477 - acc: 0.1071     \n",
      "Epoch 4/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.2399 - acc: 0.1538Epoch 00003: acc improved from 0.10714 to 0.14286, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.2401 - acc: 0.1429     \n",
      "Epoch 5/50\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 3.2292 - acc: 0.1739Epoch 00004: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 3.2305 - acc: 0.1429     \n",
      "Epoch 6/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 3.2148 - acc: 0.2500Epoch 00005: acc improved from 0.14286 to 0.21429, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.2186 - acc: 0.2143     \n",
      "Epoch 7/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 3.2071 - acc: 0.1250Epoch 00006: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 3.2002 - acc: 0.1786     \n",
      "Epoch 8/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 3.1750 - acc: 0.1600Epoch 00007: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 3.1787 - acc: 0.1429     \n",
      "Epoch 9/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.1419 - acc: 0.2308Epoch 00008: acc improved from 0.21429 to 0.25000, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.1429 - acc: 0.2500     \n",
      "Epoch 10/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 3.0996 - acc: 0.2308Epoch 00009: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 3.0944 - acc: 0.2500     \n",
      "Epoch 11/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 3.0263 - acc: 0.2963Epoch 00010: acc improved from 0.25000 to 0.28571, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 3.0287 - acc: 0.2857     \n",
      "Epoch 12/50\n",
      "22/28 [======================>.......] - ETA: 0s - loss: 2.9574 - acc: 0.4091Epoch 00011: acc improved from 0.28571 to 0.39286, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 2.9261 - acc: 0.3929     \n",
      "Epoch 13/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 2.7946 - acc: 0.4231Epoch 00012: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 2.8090 - acc: 0.3929     \n",
      "Epoch 14/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 2.6553 - acc: 0.4231Epoch 00013: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 2.6686 - acc: 0.3929     \n",
      "Epoch 15/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 2.4805 - acc: 0.4167Epoch 00014: acc improved from 0.39286 to 0.42857, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 2.5144 - acc: 0.4286     \n",
      "Epoch 16/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 2.3685 - acc: 0.5385Epoch 00015: acc improved from 0.42857 to 0.50000, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 2.3538 - acc: 0.5000     \n",
      "Epoch 17/50\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 2.1834 - acc: 0.5217Epoch 00016: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 2.1940 - acc: 0.4643     \n",
      "Epoch 18/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 2.0226 - acc: 0.6154Epoch 00017: acc improved from 0.50000 to 0.57143, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 2.0366 - acc: 0.5714     \n",
      "Epoch 19/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.8444 - acc: 0.6296Epoch 00018: acc improved from 0.57143 to 0.60714, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.8750 - acc: 0.6071     \n",
      "Epoch 20/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 1.6470 - acc: 0.6250Epoch 00019: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 1.7272 - acc: 0.6071     \n",
      "Epoch 21/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.5874 - acc: 0.6667Epoch 00020: acc improved from 0.60714 to 0.64286, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.5905 - acc: 0.6429     \n",
      "Epoch 22/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.4836 - acc: 0.6296Epoch 00021: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 1.4634 - acc: 0.6429     \n",
      "Epoch 23/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 1.3395 - acc: 0.6800Epoch 00022: acc improved from 0.64286 to 0.67857, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.3460 - acc: 0.6786     \n",
      "Epoch 24/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 1.2930 - acc: 0.6667Epoch 00023: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 1.2542 - acc: 0.6786     \n",
      "Epoch 25/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 1.0535 - acc: 0.7917Epoch 00024: acc improved from 0.67857 to 0.71429, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.1608 - acc: 0.7143     \n",
      "Epoch 26/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 1.0462 - acc: 0.8148Epoch 00025: acc improved from 0.71429 to 0.78571, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.0731 - acc: 0.7857     \n",
      "Epoch 27/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 1.0070 - acc: 0.8000Epoch 00026: acc improved from 0.78571 to 0.82143, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 1.0016 - acc: 0.8214     \n",
      "Epoch 28/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.9305 - acc: 0.7917Epoch 00027: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.9311 - acc: 0.8214     \n",
      "Epoch 29/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.8521 - acc: 0.9259Epoch 00028: acc improved from 0.82143 to 0.89286, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 0.8717 - acc: 0.8929     \n",
      "Epoch 30/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.8104 - acc: 0.9231Epoch 00029: acc improved from 0.89286 to 0.92857, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 0.8085 - acc: 0.9286     \n",
      "Epoch 31/50\n",
      "23/28 [=======================>......] - ETA: 0s - loss: 0.8047 - acc: 0.8696Epoch 00030: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.7469 - acc: 0.8929     \n",
      "Epoch 32/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.6677 - acc: 0.9600Epoch 00031: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.7084 - acc: 0.9286     \n",
      "Epoch 33/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.6888 - acc: 0.9200Epoch 00032: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.6565 - acc: 0.9286     \n",
      "Epoch 34/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.6125 - acc: 0.8846Epoch 00033: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.6207 - acc: 0.8929     \n",
      "Epoch 35/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.6000 - acc: 0.9200Epoch 00034: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.5840 - acc: 0.9286     \n",
      "Epoch 36/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.5503 - acc: 0.9200Epoch 00035: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.5477 - acc: 0.9286     \n",
      "Epoch 37/50\n",
      "26/28 [==========================>...] - ETA: 0s - loss: 0.5164 - acc: 0.9231Epoch 00036: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.5210 - acc: 0.8929     \n",
      "Epoch 38/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.4889 - acc: 0.8800Epoch 00037: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.4935 - acc: 0.8929     \n",
      "Epoch 39/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.4487 - acc: 0.9200Epoch 00038: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.4617 - acc: 0.8929     \n",
      "Epoch 40/50\n",
      "22/28 [======================>.......] - ETA: 0s - loss: 0.3831 - acc: 0.9545Epoch 00039: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.4317 - acc: 0.8929     \n",
      "Epoch 41/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3806 - acc: 0.9600Epoch 00040: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.4133 - acc: 0.9286     \n",
      "Epoch 42/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.3814 - acc: 0.9167Epoch 00041: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.3950 - acc: 0.9286     \n",
      "Epoch 43/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3768 - acc: 0.8800Epoch 00042: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.3709 - acc: 0.8929     \n",
      "Epoch 44/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3301 - acc: 0.9200Epoch 00043: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.3426 - acc: 0.8929     \n",
      "Epoch 45/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3325 - acc: 0.9600Epoch 00044: acc improved from 0.92857 to 0.96429, saving model to test.hdf5\n",
      "28/28 [==============================] - 0s - loss: 0.3262 - acc: 0.9643     \n",
      "Epoch 46/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.3307 - acc: 0.9600Epoch 00045: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.3075 - acc: 0.9643     \n",
      "Epoch 47/50\n",
      "24/28 [========================>.....] - ETA: 0s - loss: 0.3213 - acc: 0.9167Epoch 00046: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.3024 - acc: 0.9286     \n",
      "Epoch 48/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.2733 - acc: 0.9600Epoch 00047: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.2927 - acc: 0.9286     \n",
      "Epoch 49/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.2534 - acc: 0.9600Epoch 00048: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.2709 - acc: 0.9286     \n",
      "Epoch 50/50\n",
      "25/28 [=========================>....] - ETA: 0s - loss: 0.2592 - acc: 0.9200Epoch 00049: acc did not improve\n",
      "28/28 [==============================] - 0s - loss: 0.2608 - acc: 0.9286     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3eff64c50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"test.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.fit(X, y, batch_size=1, nb_epoch=50, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 96.43%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [corpora.token2id[c] for c in inp]\n",
    "    idxs = np.reshape(idxs, (1, seq_length, 1))\n",
    "    #idxs = idxs / float(len(corpora))\n",
    "    prediction = model.predict(idxs, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = corpora.id2token[index]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_emb(inp):\n",
    "    idxs = [corpora.token2id[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    print(np.array(idxs))\n",
    "    print(arrs)\n",
    "    p = model.predict(arrs)[0]\n",
    "    return corpora.id2token[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0]\n",
      "[[2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_emb(['One', 'two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cases_text = pd.read_csv('./data/test_cases_text.csv')\n",
    "pred = []\n",
    "for index, row in test_cases_text.iterrows():\n",
    "    #print( '%s %s'%(row['in_0'], row['in_1']))\n",
    "    inp = [row['in_0'], row['in_1']]\n",
    "    #print(inp)\n",
    "    tmp = get_next_emb(inp)\n",
    "    pred.append(tmp)\n",
    "test_cases_text['predicted'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_0</th>\n",
       "      <th>in_1</th>\n",
       "      <th>out</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>doing</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   in_0 in_1    out predicted\n",
       "26  are  you  doing         ?"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases_text[test_cases_text.out!=test_cases_text.predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cnt: 27 All cnt 28\n",
      "Precision: 0.96\n"
     ]
    }
   ],
   "source": [
    "true_cnt = len(test_cases_text[test_cases_text.out==test_cases_text.predicted].index) * 1.0\n",
    "all_cnt = len(test_cases_text.index) * 1.0\n",
    "print('True cnt: %d All cnt %d'%(true_cnt, all_cnt))\n",
    "print(\"Precision: %.2f\"%( true_cnt/all_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
