{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Input, Embedding, Flatten, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpora: 26\n"
     ]
    }
   ],
   "source": [
    "corpora = gensim.corpora.Dictionary.load('./data/corpora.dat')\n",
    "vocab_size = len(corpora)\n",
    "print('Number of words in corpora: %d'%(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = list(corpora.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the_filename = './data/wonderland.txt.dat'\n",
    "the_filename = './data/test.txt.dat'\n",
    "with open(the_filename, 'rb') as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate words patterns - 2 words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = 2\n",
    "c1_dat = [text[i] for i in range(0, len(text)-cs, cs)]\n",
    "c2_dat = [text[i+1] for i in range(0, len(text)-cs, cs)]\n",
    "c3_dat = [text[i+2] for i in range(0, len(text)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1 = [corpora.id2token[id] for id in c1_dat]\n",
    "tmp2 = [corpora.id2token[id] for id in c2_dat]\n",
    "tmp3 = [corpora.id2token[id] for id in c3_dat]\n",
    "#tmp1, tmp2, tmp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "x1 = np.stack(c1_dat[:])\n",
    "x2 = np.stack(c2_dat[:])\n",
    "# outputs\n",
    "y = np.stack(c3_dat[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4,  3,  5,  7, 10, 13, 15, 16, 18, 10, 21, 20, 21]),\n",
       " array([ 0,  8,  6,  9,  1, 12, 11, 17, 19, 14, 22, 23, 25, 23]),\n",
       " array([ 4,  3,  5,  7, 10, 13, 15, 16, 18, 10, 21, 20, 21, 24]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14,), (14,), (14,))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create inputs and embedding outputs for each of our 3 character inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_hidden = Dense(n_hidden, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c2_dense = dense_in(c2)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c3_out = dense_out(c2_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in], c3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c1 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c2 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)         (None, 1, 4)          104         c1[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)         (None, 1, 4)          104         c2[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 4)             0           embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 256)           1280        flatten_11[0][0]                 \n",
      "                                                                   flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 4)             0           embedding_12[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 256)           65792       dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 256)           0           dense_16[1][0]                   \n",
      "                                                                   dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 26)            6682        merge_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 73962\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 372.00 483.00\" width=\"372pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 368,-479 368,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140017213417624 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140017213417624</title>\n",
       "<polygon fill=\"none\" points=\"35.5,-438.5 35.5,-474.5 137.5,-474.5 137.5,-438.5 35.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-452.8\">c1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140017213418576 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140017213418576</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 173,-401.5 173,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-379.8\">embedding_11 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140017213417624&#45;&gt;140017213418576 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140017213417624-&gt;140017213418576</title>\n",
       "<path d=\"M86.5,-438.313C86.5,-430.289 86.5,-420.547 86.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"90.0001,-411.529 86.5,-401.529 83.0001,-411.529 90.0001,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213418632 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140017213418632</title>\n",
       "<polygon fill=\"none\" points=\"226.5,-438.5 226.5,-474.5 328.5,-474.5 328.5,-438.5 226.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-452.8\">c2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140017213444280 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140017213444280</title>\n",
       "<polygon fill=\"none\" points=\"191,-365.5 191,-401.5 364,-401.5 364,-365.5 191,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-379.8\">embedding_12 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140017213418632&#45;&gt;140017213444280 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140017213418632-&gt;140017213444280</title>\n",
       "<path d=\"M277.5,-438.313C277.5,-430.289 277.5,-420.547 277.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"281,-411.529 277.5,-401.529 274,-411.529 281,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213400960 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140017213400960</title>\n",
       "<polygon fill=\"none\" points=\"50.5,-292.5 50.5,-328.5 172.5,-328.5 172.5,-292.5 50.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"111.5\" y=\"-306.8\">flatten_11 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140017213418576&#45;&gt;140017213400960 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140017213418576-&gt;140017213400960</title>\n",
       "<path d=\"M92.5518,-365.313C95.4384,-357.115 98.9566,-347.123 102.174,-337.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"105.484,-339.124 105.504,-328.529 98.8813,-336.799 105.484,-339.124\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213400120 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140017213400120</title>\n",
       "<polygon fill=\"none\" points=\"203.5,-292.5 203.5,-328.5 325.5,-328.5 325.5,-292.5 203.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-306.8\">flatten_12 (Flatten)</text>\n",
       "</g>\n",
       "<!-- 140017213444280&#45;&gt;140017213400120 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140017213444280-&gt;140017213400120</title>\n",
       "<path d=\"M274.353,-365.313C272.884,-357.289 271.1,-347.547 269.456,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272.862,-337.735 267.618,-328.529 265.976,-338.996 272.862,-337.735\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213399336 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140017213399336</title>\n",
       "<polygon fill=\"none\" points=\"130.5,-219.5 130.5,-255.5 244.5,-255.5 244.5,-219.5 130.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-233.8\">dense_16 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140017213400960&#45;&gt;140017213399336 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140017213400960-&gt;140017213399336</title>\n",
       "<path d=\"M129.897,-292.313C139.513,-283.33 151.434,-272.193 161.932,-262.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"164.354,-264.913 169.272,-255.529 159.575,-259.798 164.354,-264.913\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017212988104 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140017212988104</title>\n",
       "<polygon fill=\"none\" points=\"88.5,-146.5 88.5,-182.5 202.5,-182.5 202.5,-146.5 88.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"145.5\" y=\"-160.8\">dense_17 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140017213399336&#45;&gt;140017212988104 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140017213399336-&gt;140017212988104</title>\n",
       "<path d=\"M177.333,-219.313C172.38,-210.941 166.321,-200.697 160.823,-191.403\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.677,-189.354 155.573,-182.529 157.652,-192.918 163.677,-189.354\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213018240 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140017213018240</title>\n",
       "<polygon fill=\"none\" points=\"131,-73.5 131,-109.5 244,-109.5 244,-73.5 131,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-87.8\">merge_6 (Merge)</text>\n",
       "</g>\n",
       "<!-- 140017213399336&#45;&gt;140017213018240 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140017213399336-&gt;140017213018240</title>\n",
       "<path d=\"M197.455,-219.306C202.773,-209.117 208.773,-195.742 211.5,-183 214.942,-166.92 214.942,-162.08 211.5,-146 209.519,-136.742 205.809,-127.15 201.889,-118.689\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"205.016,-117.115 197.455,-109.694 198.737,-120.211 205.016,-117.115\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017213400120&#45;&gt;140017213399336 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140017213400120-&gt;140017213399336</title>\n",
       "<path d=\"M245.86,-292.313C236.119,-283.33 224.041,-272.193 213.404,-262.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"215.692,-259.735 205.968,-255.529 210.947,-264.881 215.692,-259.735\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017212988104&#45;&gt;140017213018240 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140017212988104-&gt;140017213018240</title>\n",
       "<path d=\"M155.667,-146.313C160.62,-137.941 166.679,-127.697 172.177,-118.403\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"175.348,-119.918 177.427,-109.529 169.323,-116.354 175.348,-119.918\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140017212988384 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140017212988384</title>\n",
       "<polygon fill=\"none\" points=\"130.5,-0.5 130.5,-36.5 244.5,-36.5 244.5,-0.5 130.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-14.8\">dense_18 (Dense)</text>\n",
       "</g>\n",
       "<!-- 140017213018240&#45;&gt;140017212988384 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140017213018240-&gt;140017212988384</title>\n",
       "<path d=\"M187.5,-73.3129C187.5,-65.2895 187.5,-55.5475 187.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"191,-46.5288 187.5,-36.5288 184,-46.5289 191,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"dev_fast_ai_simple_model_weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 3.2659 - acc: 0.0000e+00Epoch 00000: acc improved from -inf to 0.00000, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 3.2648 - acc: 0.0000e+00     \n",
      "Epoch 2/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 3.2164 - acc: 0.1000Epoch 00001: acc improved from 0.00000 to 0.07143, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 3.2140 - acc: 0.0714     \n",
      "Epoch 3/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 3.1505 - acc: 0.3000Epoch 00002: acc improved from 0.07143 to 0.21429, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 3.1552 - acc: 0.2143     \n",
      "Epoch 4/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 3.0762 - acc: 0.4000    Epoch 00003: acc improved from 0.21429 to 0.35714, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 3.0697 - acc: 0.3571     \n",
      "Epoch 5/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 3.0102 - acc: 0.1250Epoch 00004: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.9419 - acc: 0.1429     \n",
      "Epoch 6/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 2.7527 - acc: 0.2500    Epoch 00005: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.7765 - acc: 0.1429     \n",
      "Epoch 7/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 2.6606 - acc: 0.1250    Epoch 00006: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.5706 - acc: 0.2857     \n",
      "Epoch 8/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.4271 - acc: 0.2000    Epoch 00007: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.3788 - acc: 0.2857     \n",
      "Epoch 9/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 2.1815 - acc: 0.3000    Epoch 00008: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.2517 - acc: 0.2857     \n",
      "Epoch 10/100\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 2.0396 - acc: 0.3333Epoch 00009: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.1360 - acc: 0.2857     \n",
      "Epoch 11/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.8862 - acc: 0.4000Epoch 00010: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 2.0222 - acc: 0.2857     \n",
      "Epoch 12/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.7980 - acc: 0.3750Epoch 00011: acc improved from 0.35714 to 0.42857, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 1.8839 - acc: 0.4286     \n",
      "Epoch 13/100\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 1.5825 - acc: 0.8333Epoch 00012: acc improved from 0.42857 to 0.50000, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 1.7502 - acc: 0.5000     \n",
      "Epoch 14/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 1.6193 - acc: 0.5000Epoch 00013: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 1.6415 - acc: 0.5000     \n",
      "Epoch 15/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.5063 - acc: 0.4000Epoch 00014: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 1.5088 - acc: 0.5000     \n",
      "Epoch 16/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.3512 - acc: 0.5833Epoch 00015: acc improved from 0.50000 to 0.57143, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 1.3814 - acc: 0.5714     \n",
      "Epoch 17/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 1.2046 - acc: 0.8000Epoch 00016: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 1.2885 - acc: 0.5714     \n",
      "Epoch 18/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.1796 - acc: 0.5833Epoch 00017: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 1.1656 - acc: 0.5714     \n",
      "Epoch 19/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 1.1046 - acc: 0.5000Epoch 00018: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 1.0748 - acc: 0.5714     \n",
      "Epoch 20/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.9556 - acc: 0.6667Epoch 00019: acc improved from 0.57143 to 0.71429, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 0.9753 - acc: 0.7143     \n",
      "Epoch 21/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.9107 - acc: 0.7500Epoch 00020: acc improved from 0.71429 to 0.78571, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 0.8875 - acc: 0.7857     \n",
      "Epoch 22/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.7571 - acc: 0.8333Epoch 00021: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.8165 - acc: 0.7857     \n",
      "Epoch 23/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.7461 - acc: 0.7500Epoch 00022: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.7331 - acc: 0.7857     \n",
      "Epoch 24/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.6376 - acc: 0.9167Epoch 00023: acc improved from 0.78571 to 0.85714, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 0.6652 - acc: 0.8571     \n",
      "Epoch 25/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.6702 - acc: 0.8333Epoch 00024: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.6211 - acc: 0.8571     \n",
      "Epoch 26/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.5438 - acc: 0.8333Epoch 00025: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.5796 - acc: 0.7857     \n",
      "Epoch 27/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4939 - acc: 0.9000Epoch 00026: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.5247 - acc: 0.8571     \n",
      "Epoch 28/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.4844 - acc: 1.0000Epoch 00027: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.4752 - acc: 0.8571     \n",
      "Epoch 29/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.4959 - acc: 0.8000Epoch 00028: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.4408 - acc: 0.8571     \n",
      "Epoch 30/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3755 - acc: 0.9167Epoch 00029: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.4117 - acc: 0.8571     \n",
      "Epoch 31/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3672 - acc: 0.9167Epoch 00030: acc improved from 0.85714 to 0.92857, saving model to dev_fast_ai_simple_model_weights.best.hdf5\n",
      "14/14 [==============================] - 0s - loss: 0.3672 - acc: 0.9286     \n",
      "Epoch 32/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3889 - acc: 0.9167Epoch 00031: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.3541 - acc: 0.9286     \n",
      "Epoch 33/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3734 - acc: 0.9167Epoch 00032: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.3330 - acc: 0.9286     \n",
      "Epoch 34/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.3280 - acc: 0.8333Epoch 00033: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.3021 - acc: 0.8571     \n",
      "Epoch 35/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2651 - acc: 0.9167Epoch 00034: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2801 - acc: 0.9286     \n",
      "Epoch 36/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2908 - acc: 0.9167Epoch 00035: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2649 - acc: 0.9286     \n",
      "Epoch 37/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2742 - acc: 0.9167Epoch 00036: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2438 - acc: 0.9286     \n",
      "Epoch 38/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2587 - acc: 0.8750Epoch 00037: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2382 - acc: 0.9286     \n",
      "Epoch 39/100\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.1339 - acc: 1.0000Epoch 00038: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2371 - acc: 0.9286     \n",
      "Epoch 40/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.2328 - acc: 0.9000Epoch 00039: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2231 - acc: 0.9286     \n",
      "Epoch 41/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.3140 - acc: 0.8750Epoch 00040: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2257 - acc: 0.9286     \n",
      "Epoch 42/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1731 - acc: 0.9167Epoch 00041: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2063 - acc: 0.8571     \n",
      "Epoch 43/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2270 - acc: 0.8333Epoch 00042: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.2031 - acc: 0.8571     \n",
      "Epoch 44/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1455 - acc: 1.0000Epoch 00043: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1993 - acc: 0.9286     \n",
      "Epoch 45/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2202 - acc: 0.8333Epoch 00044: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1932 - acc: 0.8571     \n",
      "Epoch 46/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.2138 - acc: 0.8333Epoch 00045: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1881 - acc: 0.8571     \n",
      "Epoch 47/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1755 - acc: 0.9167Epoch 00046: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1752 - acc: 0.9286     \n",
      "Epoch 48/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1394 - acc: 0.9167Epoch 00047: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1871 - acc: 0.8571     \n",
      "Epoch 49/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1729 - acc: 0.9167Epoch 00048: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1658 - acc: 0.9286     \n",
      "Epoch 50/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1884 - acc: 0.8333Epoch 00049: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1671 - acc: 0.8571     \n",
      "Epoch 51/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1827 - acc: 0.9167Epoch 00050: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1611 - acc: 0.9286     \n",
      "Epoch 52/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0596 - acc: 1.0000Epoch 00051: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1551 - acc: 0.9286     \n",
      "Epoch 53/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1292 - acc: 0.9000Epoch 00052: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1619 - acc: 0.8571     \n",
      "Epoch 54/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1342 - acc: 0.9000Epoch 00053: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1568 - acc: 0.8571     \n",
      "Epoch 55/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1098 - acc: 0.9000Epoch 00054: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1682 - acc: 0.8571     \n",
      "Epoch 56/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1875 - acc: 0.9000Epoch 00055: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1558 - acc: 0.9286     \n",
      "Epoch 57/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1916 - acc: 0.9000Epoch 00056: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1459 - acc: 0.9286     \n",
      "Epoch 58/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0489 - acc: 1.0000Epoch 00057: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1437 - acc: 0.9286     \n",
      "Epoch 59/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1598 - acc: 0.9167Epoch 00058: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1511 - acc: 0.9286     \n",
      "Epoch 60/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1591 - acc: 0.9167Epoch 00059: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1398 - acc: 0.9286     \n",
      "Epoch 61/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1521 - acc: 0.9167Epoch 00060: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1344 - acc: 0.9286     \n",
      "Epoch 62/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1645 - acc: 0.9167Epoch 00061: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1432 - acc: 0.9286     \n",
      "Epoch 63/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1884 - acc: 0.9000Epoch 00062: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1403 - acc: 0.9286     \n",
      "Epoch 64/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0972 - acc: 1.0000Epoch 00063: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1422 - acc: 0.9286     \n",
      "Epoch 65/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1548 - acc: 0.9167Epoch 00064: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1359 - acc: 0.9286     \n",
      "Epoch 66/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0267 - acc: 1.0000Epoch 00065: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1317 - acc: 0.9286     \n",
      "Epoch 67/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1851 - acc: 0.8000Epoch 00066: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1364 - acc: 0.8571     \n",
      "Epoch 68/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1690 - acc: 0.9000Epoch 00067: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1249 - acc: 0.9286     \n",
      "Epoch 69/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0885 - acc: 1.0000Epoch 00068: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1387 - acc: 0.9286     \n",
      "Epoch 70/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1623 - acc: 0.9000Epoch 00069: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1306 - acc: 0.9286     \n",
      "Epoch 71/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1009 - acc: 0.8750Epoch 00070: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1351 - acc: 0.8571     \n",
      "Epoch 72/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0967 - acc: 1.0000Epoch 00071: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1257 - acc: 0.9286     \n",
      "Epoch 73/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1202 - acc: 0.8750Epoch 00072: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1271 - acc: 0.8571     \n",
      "Epoch 74/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0892 - acc: 0.9167Epoch 00073: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1305 - acc: 0.8571     \n",
      "Epoch 75/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1957 - acc: 0.7500Epoch 00074: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1218 - acc: 0.8571     \n",
      "Epoch 76/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1477 - acc: 0.8333Epoch 00075: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1279 - acc: 0.8571     \n",
      "Epoch 77/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.0924 - acc: 1.0000Epoch 00076: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1388 - acc: 0.9286     \n",
      "Epoch 78/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1589 - acc: 0.8333Epoch 00077: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1380 - acc: 0.8571     \n",
      "Epoch 79/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1919 - acc: 0.8750Epoch 00078: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1217 - acc: 0.9286     \n",
      "Epoch 80/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1550 - acc: 0.9000Epoch 00079: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1169 - acc: 0.9286     \n",
      "Epoch 81/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1484 - acc: 0.8333Epoch 00080: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1330 - acc: 0.8571     \n",
      "Epoch 82/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2164 - acc: 0.7500Epoch 00081: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1277 - acc: 0.8571     \n",
      "Epoch 83/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.0681 - acc: 1.0000Epoch 00082: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1284 - acc: 0.9286     \n",
      "Epoch 84/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1966 - acc: 0.8750Epoch 00083: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1197 - acc: 0.9286     \n",
      "Epoch 85/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.2188 - acc: 0.8750Epoch 00084: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1322 - acc: 0.9286     \n",
      "Epoch 86/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0631 - acc: 1.0000Epoch 00085: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1332 - acc: 0.9286     \n",
      "Epoch 87/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1734 - acc: 0.9000Epoch 00086: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1301 - acc: 0.9286     \n",
      "Epoch 88/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1443 - acc: 0.9167Epoch 00087: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1248 - acc: 0.9286     \n",
      "Epoch 89/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0152 - acc: 1.0000Epoch 00088: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1188 - acc: 0.9286     \n",
      "Epoch 90/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0757 - acc: 1.0000Epoch 00089: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1184 - acc: 0.9286     \n",
      "Epoch 91/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0912 - acc: 0.9000Epoch 00090: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1387 - acc: 0.8571     \n",
      "Epoch 92/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0608 - acc: 1.0000Epoch 00091: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1251 - acc: 0.9286     \n",
      "Epoch 93/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0632 - acc: 1.0000Epoch 00092: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1139 - acc: 0.9286     \n",
      "Epoch 94/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.0742 - acc: 1.0000Epoch 00093: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1098 - acc: 0.9286     \n",
      "Epoch 95/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1584 - acc: 0.9000Epoch 00094: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1184 - acc: 0.9286     \n",
      "Epoch 96/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1650 - acc: 0.9000Epoch 00095: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1228 - acc: 0.9286     \n",
      "Epoch 97/100\n",
      " 8/14 [================>.............] - ETA: 0s - loss: 0.1218 - acc: 0.8750Epoch 00096: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1306 - acc: 0.8571     \n",
      "Epoch 98/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1336 - acc: 0.9167Epoch 00097: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1155 - acc: 0.9286     \n",
      "Epoch 99/100\n",
      "10/14 [====================>.........] - ETA: 0s - loss: 0.1484 - acc: 0.9000Epoch 00098: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1118 - acc: 0.9286     \n",
      "Epoch 100/100\n",
      "12/14 [========================>.....] - ETA: 0s - loss: 0.1287 - acc: 0.9167Epoch 00099: acc did not improve\n",
      "14/14 [==============================] - 0s - loss: 0.1134 - acc: 0.9286     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f584bdd6a20>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.optimizer.lr = 0.000001\n",
    "model.fit([x1, x2], y, batch_size=2, nb_epoch=100, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 92.86%\n"
     ]
    }
   ],
   "source": [
    "# summarize performance of the model\n",
    "scores = model.evaluate([x1, x2], y, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('./models/dev_fast_ai_simple_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload weights\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_multi(inp):\n",
    "    idxs = [corpora.token2id[c] for c in inp]\n",
    "    print(idxs)\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    print(arrs)\n",
    "    \n",
    "    p = model.predict(arrs)\n",
    "    print(p.shape)\n",
    "    i_max1 = np.argmax(p)\n",
    "    p[0,i_max1] = 0\n",
    "    i_max2 = np.argmax(p)\n",
    "    p[0,i_max2] = 0\n",
    "    i_max3 = np.argmax(p)\n",
    "\n",
    "    \n",
    "    return corpora.id2token[i_max1], corpora.id2token[i_max2], corpora.id2token[i_max3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [corpora.token2id[c] for c in inp]\n",
    "    #print(idxs)\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    #print(arrs)\n",
    "    \n",
    "    p = model.predict(arrs)\n",
    "    #print(p.shape)\n",
    "    i_max1 = np.argmax(p)\n",
    "    #p[0,i_max1] = 0\n",
    "    #i_max2 = np.argmax(p)\n",
    "    #p[0,i_max2] = 0\n",
    "    #i_max3 = np.argmax(p)\n",
    "\n",
    "    \n",
    "    return corpora.id2token[i_max1]#, corpora.id2token[i_max2], corpora.id2token[i_max3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(['One', 'two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_cases_text = pd.read_csv('./data/test_cases_text.csv')\n",
    "pred = []\n",
    "for index, row in test_cases_text.iterrows():\n",
    "    #print( '%s %s'%(row['in_0'], row['in_1']))\n",
    "    inp = [row['in_0'], row['in_1']]\n",
    "    #print(inp)\n",
    "    tmp = get_next(inp)\n",
    "    pred.append(tmp)\n",
    "test_cases_text['predicted'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_0</th>\n",
       "      <th>in_1</th>\n",
       "      <th>out</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>two</td>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>four</td>\n",
       "      <td>five</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five</td>\n",
       "      <td>six</td>\n",
       "      <td>seven</td>\n",
       "      <td>seven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seven</td>\n",
       "      <td>eight</td>\n",
       "      <td>nine</td>\n",
       "      <td>nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nine</td>\n",
       "      <td>ten</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>The</td>\n",
       "      <td>quick</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>quick</td>\n",
       "      <td>brown</td>\n",
       "      <td>fox</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fox</td>\n",
       "      <td>jumps</td>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>over</td>\n",
       "      <td>a</td>\n",
       "      <td>lazy</td>\n",
       "      <td>lazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lazy</td>\n",
       "      <td>dog</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>.</td>\n",
       "      <td>How</td>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>?</td>\n",
       "      <td>What</td>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are</td>\n",
       "      <td>you</td>\n",
       "      <td>doing</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     in_0   in_1    out predicted\n",
       "0     One    two  three     three\n",
       "2   three   four   five      five\n",
       "4    five    six  seven     seven\n",
       "6   seven  eight   nine      nine\n",
       "8    nine    ten      .         .\n",
       "10      .    The  quick     quick\n",
       "12  quick  brown    fox       fox\n",
       "14    fox  jumps   over      over\n",
       "16   over      a   lazy      lazy\n",
       "18   lazy    dog      .         .\n",
       "20      .    How    are       are\n",
       "24      ?   What    are       are\n",
       "26    are    you  doing     doing"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases_text[test_cases_text.out==test_cases_text.predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cnt: 13 All cnt 28\n",
      "Precision: 0.46\n"
     ]
    }
   ],
   "source": [
    "true_cnt = len(test_cases_text[test_cases_text.out==test_cases_text.predicted].index) * 1.0\n",
    "all_cnt = len(test_cases_text.index) * 1.0\n",
    "print('True cnt: %d All cnt %d'%(true_cnt, all_cnt))\n",
    "print(\"Precision: %.2f\"%( true_cnt/all_cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
