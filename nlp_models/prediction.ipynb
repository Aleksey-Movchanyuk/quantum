{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "from ipywidgets import widgets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'nn_3_in_1_lstm_1_out.json'\n",
    "\n",
    "#CORPORA_NAME = 'test.txt.corpora.dat'\n",
    "#MODEL_WEIGHT = 'test.txt.nn_3_in_1_lstm_1_out.weights.hdf5'\n",
    "\n",
    "CORPORA_NAME = 'en_US.blogs.txt.corpora.dat'\n",
    "MODEL_WEIGHT = 'en_US.blogs.txt.nn_3_in_1_lstm_1_out.3.1000000.weights.hdf5'\n",
    "\n",
    "IN_SEQ_LENGTH = 3\n",
    "OUT_SEQ_LENGTH = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "META_UNKNOWN = '<<<!UNK!>>>'\n",
    "META_EMPTY = '<<<!EMP!>>>'\n",
    "META_NUMBER = '<<<!NUM!>>>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpora: 20002\n"
     ]
    }
   ],
   "source": [
    "corpora = gensim.corpora.Dictionary.load('./data/'+CORPORA_NAME)\n",
    "vocab_size = len(corpora)\n",
    "print('Number of words in corpora: %d'%(vocab_size))\n",
    "tmp = list(corpora.items())\n",
    "del(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/' + MODEL_NAME, mode='r') as f:\n",
    "    model = model_from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./data/'  + MODEL_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 3, 64)         1280128     embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 1024)          4460544     embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 14)            20502050    lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 26242722\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_last_token_ids(inp, seq_len):\n",
    "    \n",
    "    res = np.full(seq_len, corpora.token2id[META_EMPTY], dtype=int)\n",
    "      \n",
    "    raw_sents = nltk.tokenize.sent_tokenize(inp.lower())\n",
    "\n",
    "    id_tokens = []\n",
    "    \n",
    "    for s in raw_sents:\n",
    "        raw_tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "       \n",
    "        for t in raw_tokens:\n",
    "            try:\n",
    "                tid = corpora.token2id[t]\n",
    "            except:\n",
    "                tid = corpora.token2id[META_UNKNOWN]\n",
    "            id_tokens.append(tid)\n",
    "            #print('%s -> %d'%(t, tid))\n",
    "\n",
    "    l = min(seq_len, len(id_tokens))\n",
    "    s = seq_len - l\n",
    "    #print(id_tokens)\n",
    "    #print(id_tokens[-l:])\n",
    "    \n",
    "    res[s:] = id_tokens[-l:]\n",
    "       \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_word(inp):\n",
    "    tids = get_last_token_ids(inp, IN_SEQ_LENGTH)\n",
    "    arrs = np.array(tids)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    #print(p)\n",
    "    \n",
    "    m0 = np.argmax(p); p0 = p[m0]; p[m0] = 0\n",
    "    m1 = np.argmax(p); p1 = p[m1]; p[m1] = 0\n",
    "    m2 = np.argmax(p); p2 = p[m2]; p[m2] = 0\n",
    "    m3 = np.argmax(p); p3 = p[m3]; p[m3] = 0\n",
    "    m4 = np.argmax(p); p4 = p[m4]; p[m4] = 0\n",
    "    m5 = np.argmax(p); p5 = p[m5]; p[m5] = 0\n",
    "    m6 = np.argmax(p); p6 = p[m6]; p[m6] = 0\n",
    "    \n",
    "    return [(p0, corpora.id2token[m0]),\n",
    "            (p1, corpora.id2token[m1]),\n",
    "            (p2, corpora.id2token[m2]),\n",
    "            (p3, corpora.id2token[m3]),\n",
    "            (p4, corpora.id2token[m4]),\n",
    "            (p5, corpora.id2token[m5]),\n",
    "            (p6, corpora.id2token[m6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_words_beam = []\n",
    "\n",
    "def get_next_words_requesive(inp, seq_len, prob=1.0):\n",
    "        \n",
    "    if seq_len == 0 :\n",
    "        return\n",
    "    \n",
    "    pred = get_next_word(inp)\n",
    "    \n",
    "    for p in pred:\n",
    "        if len(inp) > 0: \n",
    "            s = inp + ' ' + p[1]\n",
    "        else:\n",
    "            s = p[1]\n",
    "        #print(s)\n",
    "        if seq_len > 1 :\n",
    "            get_next_words_requesive(s, seq_len-1, prob*p[0])\n",
    "        else:\n",
    "            #print( '%s %f'%(s, prob*p[1]) )\n",
    "            next_words_beam.append( (prob*p[0], s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_words(inp, words_to_predict, top=10):\n",
    "    \n",
    "    next_words_beam.clear()\n",
    "    \n",
    "    get_next_words_requesive(inp, words_to_predict)\n",
    "    \n",
    "    next_words_beam.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return next_words_beam[:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13940275, 'i'),\n",
       " (0.071074374, 'the'),\n",
       " (0.046676371, 'it'),\n",
       " (0.031658143, 'and'),\n",
       " (0.024488971, 'this'),\n",
       " (0.022508644, 'but'),\n",
       " (0.021897659, 'we')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_word('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12810064852237701, 'Hi everyone'),\n",
       " (0.12010793387889862, 'Hi !'),\n",
       " (0.094802573323249817, 'Hi ,'),\n",
       " (0.054005932062864304, 'Hi it'),\n",
       " (0.052542150020599365, 'Hi the'),\n",
       " (0.036244608461856842, 'Hi you'),\n",
       " (0.023914987221360207, 'Hi for')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_words('Hi', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.012725758562348588, \"i '\"),\n",
       " (0.0093280714576638446, \"it '\"),\n",
       " (0.0092455425771342803, 'i have'),\n",
       " (0.0081878243198056921, 'this is'),\n",
       " (0.0081202295937043978, 'i ’'),\n",
       " (0.007741433969887801, 'i am'),\n",
       " (0.006880082826056122, 'it ’'),\n",
       " (0.0068554046504845645, 'it is'),\n",
       " (0.0064491832820475214, 'it was'),\n",
       " (0.0056063334160483258, 'i don')]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_words('', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.00043809224046883355, 'What do you know that ’ s'),\n",
       " (0.00032913239100016757, \"What do you know that ' s\"),\n",
       " (0.00019197904706720826, 'What do you think that ’ s'),\n",
       " (0.00018286607957294815, 'What do you want to know that'),\n",
       " (0.00014402114180568702, 'What do you know of course ,'),\n",
       " (0.00013085715655169867, 'What do you think it ’ s'),\n",
       " (0.00011256596185976002, 'What do i know that ’ s'),\n",
       " (0.00010323181508792545, \"What do you think that ' s\"),\n",
       " (8.1762451390438693e-05, \"What do you think it ' s\"),\n",
       " (7.6961083522705296e-05, 'What do you have to seen the')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_words('What do', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
