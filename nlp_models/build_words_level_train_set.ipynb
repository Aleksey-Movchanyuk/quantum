{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'test.txt'\n",
    "#filename = 'en_US.blogs.txt'\n",
    "\n",
    "IN_SEQ_LENGTH = 3\n",
    "OUT_SEQ_LENGTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "META_UNKNOWN = '<<<!UNK!>>>'\n",
    "META_EMPTY = '<<<!EMP!>>>'\n",
    "META_NUMBER = '<<<!NUM!>>>'\n",
    "\n",
    "no_below_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = [[META_UNKNOWN], [META_EMPTY], [META_NUMBER]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora = gensim.corpora.Dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to convert raw text to word ids representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_corpora(sents):\n",
    "    tmp = []\n",
    "    for s in sents:\n",
    "        words = nltk.tokenize.wordpunct_tokenize(s)\n",
    "        \n",
    "        tokens = []\n",
    "        ###############################\n",
    "        # Recognize digits and paterns\n",
    "        ###############################\n",
    "        for w in words:\n",
    "            if w.isdigit() :\n",
    "                w = META_NUMBER\n",
    "            #print(w)\n",
    "            tokens.append(w)\n",
    "        tmp.append(tokens)\n",
    "    \n",
    "    #print(tmp)\n",
    "    corpora.add_documents(tmp)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build carpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n"
     ]
    }
   ],
   "source": [
    "# read source file\n",
    "print('Reading file...')\n",
    "raw_text = open('./raw_texts/' + filename).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences...\n"
     ]
    }
   ],
   "source": [
    "# get raw sentences\n",
    "print('Parsing sentences...')\n",
    "raw_sents = nltk.tokenize.sent_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update corpora\n",
    "update_corpora(raw_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out low frequent tokens\n",
    "corpora.filter_extremes(no_below=no_below_tokens, no_above=0.8, keep_n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add meta symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora.add_documents(meta)\n",
    "#corpora.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Convert raw sentences in ids sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get id sentences\n",
    "id_sents = []\n",
    "for s in raw_sents:\n",
    "    raw_tokens = nltk.tokenize.wordpunct_tokenize(s)\n",
    "    id_tokens = []\n",
    "    for t in raw_tokens:\n",
    "        try:\n",
    "            tid = corpora.token2id[t]\n",
    "        except:\n",
    "            tid = corpora.token2id[META_UNKNOWN]\n",
    "        id_tokens.append(tid)\n",
    "    id_sents.append(id_tokens)\n",
    "    #print(raw_tokens)\n",
    "    #print(id_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 4\n"
     ]
    }
   ],
   "source": [
    "print('Sentences %d'%(len(id_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/'+filename+'.id.dat', 'wb') as f:\n",
    "    pickle.dump(id_sents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(raw_sents)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpora info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = list(corpora.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpora.save('./data/' + filename + '.corpora.dat')\n",
    "corpora.save_as_text('./data/'+filename+'.corpora.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpora: 29\n"
     ]
    }
   ],
   "source": [
    "print('Number of words in corpora: %d'%(len(corpora)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpora.id2token[15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(tmp)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data (recovery steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in corpora: 29\n"
     ]
    }
   ],
   "source": [
    "corpora = gensim.corpora.Dictionary.load('./data/'+filename+'.corpora.dat')\n",
    "vocab_size = len(corpora)\n",
    "print('Number of words in corpora: %d'%(vocab_size))\n",
    "tmp = list(corpora.items())\n",
    "del(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences 4\n"
     ]
    }
   ],
   "source": [
    "with open('./data/'+filename+'.id.dat', 'rb') as f:\n",
    "    id_sents = pickle.load(f)\n",
    "    \n",
    "print('Sentences %d'%(len(id_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert raw text to ids text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_META_EMPTY = corpora.token2id[META_EMPTY]\n",
    "ID_META_UNKNOWN = corpora.token2id[META_UNKNOWN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_text = []\n",
    "\n",
    "for id_s in id_sents:\n",
    "    for id_t in id_s:\n",
    "        id_text.append(id_t)\n",
    "    \n",
    "id_text = np.array(id_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 30\n"
     ]
    }
   ],
   "source": [
    "print('Tokens: %d'%(len(id_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### BUILD TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_header(sufix, count):\n",
    "    line = ''\n",
    "    for i in range(0, count, 1):\n",
    "        if i > 0:\n",
    "            line += ','\n",
    "        line += sufix + '_' + str(i)\n",
    "    return line + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_line(a):\n",
    "    line = ''\n",
    "    for i in range(0, a.shape[0],1):\n",
    "        if i > 0:\n",
    "            line += ','\n",
    "        line += str(a[i])\n",
    "    return line + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csv_header('in', IN_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csv_line( np.array([1,2,3,4,5]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_train_X = open('./data/' + filename + '.' + str(IN_SEQ_LENGTH) + '_in_' + str(OUT_SEQ_LENGTH) + '_out.train_X.csv', 'wt')\n",
    "f_train_Y = open('./data/' + filename + '.' + str(IN_SEQ_LENGTH) + '_in_' + str(OUT_SEQ_LENGTH) + '_out.train_Y.csv', 'wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_train_X.write(csv_header('in', IN_SEQ_LENGTH))\n",
    "f_train_Y.write(csv_header('out', OUT_SEQ_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_X = []\n",
    "#train_Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id_s in id_sents:\n",
    "    \n",
    "    if len(id_s) < 2 :\n",
    "        continue\n",
    "    \n",
    "    for shift_i in range(0, IN_SEQ_LENGTH, 1):\n",
    "    \n",
    "        seq_in = np.full((IN_SEQ_LENGTH), ID_META_EMPTY, dtype=int)\n",
    "        if shift_i > 0 :\n",
    "            for ii in range(0, shift_i, 1):\n",
    "                seq_in[IN_SEQ_LENGTH-shift_i+ii] = id_s[ii]\n",
    "    \n",
    "        #print(shift_i)\n",
    "        seq_out = np.full((OUT_SEQ_LENGTH), ID_META_EMPTY, dtype=int)\n",
    "        for oi in range(0, min(OUT_SEQ_LENGTH,len(id_s)), 1):          \n",
    "            if oi+shift_i < len(id_s):\n",
    "                seq_out[oi] = id_s[oi+shift_i]\n",
    "        \n",
    "        if np.any(seq_out!=ID_META_UNKNOWN) & np.all(seq_in!=ID_META_UNKNOWN) :\n",
    "            f_train_X.write(csv_line(seq_in))\n",
    "            f_train_Y.write(csv_line(seq_out))\n",
    "            seq_cnt += 1\n",
    "            if (seq_cnt % 1000)==0 :\n",
    "                f_train_X.flush()\n",
    "                f_train_Y.flush()\n",
    "            #train_X.append(list(seq_in))\n",
    "            #train_Y.append(list(seq_out))\n",
    "            #print('Shift: {}, {} -> {}'.format(shift_i, seq_in, seq_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(id_sents)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip the next calculation if any data issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#seq_in = []\n",
    "#seq_out = []\n",
    "for i in range(0, len(id_text)-IN_SEQ_LENGTH-OUT_SEQ_LENGTH+1, 1):\n",
    "    seq_in = id_text[i:i+IN_SEQ_LENGTH]\n",
    "    seq_out = id_text[i+IN_SEQ_LENGTH:i+IN_SEQ_LENGTH+OUT_SEQ_LENGTH]\n",
    "    #print('{} -> {}'.format(seq_in, seq_out))\n",
    "    \n",
    "    if np.any(seq_out!=ID_META_UNKNOWN) & np.all(seq_in!=ID_META_UNKNOWN) :\n",
    "        f_train_X.write(csv_line(seq_in))\n",
    "        f_train_Y.write(csv_line(seq_out))\n",
    "        seq_cnt += 1\n",
    "        if (seq_cnt % 1000)==0 :\n",
    "            f_train_X.flush()\n",
    "            f_train_Y.flush()\n",
    "\n",
    "        #train_X.append(list(seq_in))\n",
    "        #train_Y.append(list(seq_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_train_Y.close()\n",
    "f_train_X.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('Train set X, Y:')\n",
    "#print( len(train_X), len(train_Y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 37\n"
     ]
    }
   ],
   "source": [
    "print('Train set: %d'%(seq_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_X[1000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('./data/'+filename+'.train_X.dat', 'wb') as f:\n",
    "#    pickle.dump(train_X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('./data/'+filename+'.train_Y.dat', 'wb') as f:\n",
    "#    pickle.dump(train_Y, f)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
